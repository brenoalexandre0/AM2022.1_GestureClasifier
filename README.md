# AM-2022.1---Gesture-Classifier
- Machine Learning Project, from the first semestter of 2022, tutored by Prof. Dr. FabrÃ­cio Braz
- Model identifies hand gestures in an image
- Model trained in HaGRID, with a smaller database, as it is originally extensive

## Identifiable gestures
- ğŸ¤™ call
- ğŸ‘ dislike
- âœŠ fist
- ğŸ–ï¸ four (ignore one finger here)
- ğŸ‘ like
- ğŸ¤­ mute
- ğŸ‘Œ ok
- ğŸ‘† one
- âœ‹ palm
- âœŒï¸ peace
- âœŒï¸ peace_inverted
- ğŸ¤˜ rock
- âœ‹ stop
- ğŸ¤š stop_inverted
- ğŸ–ï¸ three (ignore two fingers  here)
- ğŸ–ï¸ three2 (ignore two fingers  here)
- âœŒï¸ two_up (pretend the two raised fingers are close)
- âœŒï¸ two_up_inverted (pretend the two raised fingers are close)

## Step by step
- Start the blocks
- Modify the path where the files will be uploaded from
- Load batch and confusion matrix
- Insert an image with any of the above hand gestures to be classified
- The classification is generated

## Screenshots
![image](https://github.com/brenoalexandre0/AM-2022.1---Gesture-Classifier/assets/80782792/9e8b3f8b-2ad8-4e32-927c-ff9b02b2feed)


## Installation
Language: Jupyther Notebook
Framework: fast.ai, fastbook, resnet18, resnet152

## Original model
https://github.com/hukenovs/hagrid
